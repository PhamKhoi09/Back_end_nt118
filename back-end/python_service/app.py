import os
import uuid
import numpy as np
import librosa
import requests
import whisper
from scipy.spatial.distance import euclidean
from fastdtw import fastdtw
from flask import Flask, request, jsonify
from difflib import SequenceMatcher

app = Flask(_name_)

# 1. Load AI Model (Whisper)
print("â³ Loading Whisper...")
model = whisper.load_model("base")
print("âœ… Whisper Ready!")

# =======================
# MODULE 1: Xá»¬ LÃ CAO Äá»˜ (NON-AI / DSP)
# =======================
def extract_pitch_contour(y, sr):
    # Sá»­ dá»¥ng thuáº­t toÃ¡n YIN Ä‘á»ƒ trÃ­ch xuáº¥t cao Ä‘á»™ (F0)
    # fmin=50Hz, fmax=400Hz (VÃ¹ng giá»ng nÃ³i con ngÆ°á»i)
    f0, voiced_flag, _ = librosa.pyin(y, fmin=50, fmax=400, sr=sr)
    
    # Thay tháº¿ cÃ¡c giÃ¡ trá»‹ NaN (khÃ´ng cÃ³ tiáº¿ng) báº±ng 0
    f0 = np.nan_to_num(f0)
    
    # Chá»‰ láº¥y nhá»¯ng Ä‘oáº¡n cÃ³ tiáº¿ng (Voiced) Ä‘á»ƒ so sÃ¡nh
    # VÃ¬ Ä‘oáº¡n im láº·ng cao Ä‘á»™ = 0 so sÃ¡nh sáº½ khÃ´ng chÃ­nh xÃ¡c
    return f0[f0 > 0]

def compare_intonation(user_path, ref_path):
    try:
        y1, sr1 = librosa.load(user_path, sr=16000)
        y2, sr2 = librosa.load(ref_path, sr=16000)

        # TrÃ­ch xuáº¥t Ä‘Æ°á»ng cao Ä‘á»™ (Pitch)
        pitch1 = extract_pitch_contour(y1, sr1)
        pitch2 = extract_pitch_contour(y2, sr1)

        if len(pitch1) < 10 or len(pitch2) < 10:
            return 0.0 # KhÃ´ng báº¯t Ä‘Æ°á»£c giá»ng

        # --- CHUáº¨N HÃ“A CAO Äá»˜ (QUAN TRá»ŒNG) ---
        # VÃ¬ giá»ng Nam tráº§m hÆ¡n giá»ng Ná»¯. Ta khÃ´ng so sÃ¡nh Hz tuyá»‡t Ä‘á»‘i.
        # Ta so sÃ¡nh "HÃ¬nh dÃ¡ng" (Shape) cá»§a Ä‘Æ°á»ng cao Ä‘á»™ (Z-score normalization)
        pitch1_norm = (pitch1 - np.mean(pitch1)) / (np.std(pitch1) + 1e-8)
        pitch2_norm = (pitch2 - np.mean(pitch2)) / (np.std(pitch2) + 1e-8)

        # DÃ¹ng DTW Ä‘á»ƒ so sÃ¡nh hÃ¬nh dÃ¡ng 2 Ä‘Æ°á»ng cao Ä‘á»™
        distance, path = fastdtw(pitch1_norm.reshape(-1, 1), pitch2_norm.reshape(-1, 1), dist=euclidean)
        avg_dist = distance / len(path)

        # Cháº¥m Ä‘iá»ƒm Intonation
        # Dist < 0.5 lÃ  ráº¥t giá»‘ng, > 1.5 lÃ  ngÆ°á»£c tÃ´ng
        score = 100 / (0.7 + np.exp(3 * (avg_dist - 0.7)))
        
        return round(score, 1)

    except Exception as e:
        print(f"âš ï¸ Lá»—i Pitch: {e}")
        return 50.0 # Tráº£ Ä‘iá»ƒm trung bÃ¬nh náº¿u lá»—i DSP

# =======================
# MODULE 2: Xá»¬ LÃ VÄ‚N Báº¢N (AI)
# =======================
def normalize_text(text):
    return "".join(c for c in text if c.isalnum()).lower()

# =======================
# MAIN API
# =======================
@app.route('/grade', methods=['POST'])
def grade():
    user_filename = None
    ref_filename = None

    try:
        # Nháº­n dá»¯ liá»‡u
        user_file = request.files['user_audio']
        ref_url = request.form['ref_audio_url'] # URL file audio máº«u (Ä‘á»ƒ so sÃ¡nh Pitch)
        correct_word = request.form['correct_word'] # Tá»« vá»±ng Ä‘Ãºng (Ä‘á»ƒ so sÃ¡nh Text)

        random_id = str(uuid.uuid4())[:8]
        user_filename = f"user_{random_id}.wav"
        ref_filename = f"ref_{random_id}.mp3"
        
        user_file.save(user_filename)

        # Táº£i file máº«u vá» Ä‘á»ƒ phÃ¢n tÃ­ch cao Ä‘á»™
        headers = {'User-Agent': 'Mozilla/5.0'}
        response = requests.get(ref_url, headers=headers, timeout=10)
        with open(ref_filename, "wb") as f:
            f.write(response.content)

        # --- BÆ¯á»šC 1: CHáº¤M Äá»˜ CHÃNH XÃC (WHISPER AI) ---
        print("ğŸ¤– AI Ä‘ang nghe...")
        ai_result = model.transcribe(user_filename, language="en", fp16=False)
        detected_text = ai_result["text"]
        
        # So sÃ¡nh text
        text_similarity = SequenceMatcher(None, normalize_text(correct_word), normalize_text(detected_text)).ratio()
        accuracy_score = text_similarity * 100
        
        print(f"ğŸ¯ Text: {accuracy_score}% (Target: {correct_word} | User: {detected_text})")

        # --- LOGIC QUYáº¾T Äá»ŠNH ---
        final_score = 0
        intonation_score = 0
        feedback = ""

        if accuracy_score < 60:
            # Náº¿u Ä‘á»c sai tá»« -> 0 Ä‘iá»ƒm luÃ´n, khÃ´ng cáº§n cháº¥m ngá»¯ Ä‘iá»‡u
            final_score = accuracy_score
            feedback = f"Báº¡n phÃ¡t Ã¢m chÆ°a Ä‘Ãºng tá»« nÃ y. AI nghe thÃ nh: '{detected_text}'"
        else:
            # Náº¿u Ä‘á»c Ä‘Ãºng tá»« -> Cháº¥m thÃªm ngá»¯ Ä‘iá»‡u (DSP)
            print("ğŸ¼ Äang phÃ¢n tÃ­ch ngá»¯ Ä‘iá»‡u (DSP)...")
            intonation_score = compare_intonation(user_filename, ref_filename)
            print(f"ğŸ¯ Intonation: {intonation_score}%")

            # CÃ´ng thá»©c tá»•ng há»£p: 60% Äá»™ Ä‘Ãºng tá»« + 40% Ngá»¯ Ä‘iá»‡u
            final_score = (accuracy_score * 0.7) + (intonation_score * 0.3)

        return jsonify({
            "score": round(final_score, 1),
            "details": {
                "accuracy_score": round(accuracy_score, 1),
                "intonation_score": round(intonation_score, 1),
                "detected_text": detected_text
            },
        })

    except Exception as e:
        print(f"ğŸ”¥ Error: {e}")
        return jsonify({"error": str(e)}), 500

    finally:
        for f in [user_filename, ref_filename]:
            if f and os.path.exists(f):
                try: os.remove(f)
                except: pass

if _name_ == '_main_':
    app.run(port=5002, debug=True)